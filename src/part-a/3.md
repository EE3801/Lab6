# Part 3. Generating cumulative objects with slurm

## 8.
In addition to looking at data across multiple sessions, we can also look at data from individual channels. We will do this by generating additional objects on the cluster to compute the frequency content of the signals for each of the channels. In another Terminal window logged into the head node of your cluster, copy `rpllfp-slurm.sh` to create a slurm script `freq-slurm.sh` to generate low-frequency and high-frequency `FreqSpectrum` objects, which can be created with the following Python commands:

```bash
pyh.FreqSpectrum(saveLevel=1); \
pyh.FreqSpectrum(loadHighPass=True, pointsPerWindow=3000, saveLevel=1);
```

The first command will create an object with the low-frequency signals using the `rpllfp` object, while the second command will create an object with the high-frequency signals using the `rplhighpass` object. Make sure you keep the other commands like `import PyHipp as pyh` intact.

> <p class="task"> Task
>
> Include a screenshot of the completed `freq-slurm.sh` script in your lab report.

## 9.
Once the individual objects are created in the channel directories, we will want to create cumulative objects containing the low-frequency and high-frequency spectrum of all the channels. So we will make a copy of `freq-slurm.sh` to create another script `fsall-slurm.sh`, and replace the Python command with:

```bash
import DataProcessingTools as DPT; \
lfall = DPT.objects.processDirs(dirs=None, exclude=['*eye*', '*mountains*'], objtype=pyh.FreqSpectrum, saveLevel=1); \
lfall.save(); \
hfall = DPT.objects.processDirs(dirs=None, exclude=['*eye*', '*mountains*'], objtype=pyh.FreqSpectrum, loadHighPass=True, pointsPerWindow=3000, saveLevel=1); \
hfall.save();
```

The `processDirs` command in this script will load the previously saved `FreqSpectrum` objects, which were computed using parallel processing, to create the cumulative object so this will be more efficient than having one job compute the `FreqSpectrum` objects for all the channels sequentially. You might want to add the following so you will be notified when the job is done (remember to replace the account number below with your account number):

```bash
aws sns publish --topic-arn arn:aws:sns:ap-southeast-1:123456789012:awsnotify --message "FSJobDone"
```

> <p class="task"> Task
>
> Include a screenshot of the completed `fsall-slurm.sh` script in your lab report.

## 10.
The `fsall-slurm.sh` script should only run once all the `freq-slurm.sh` jobs are done, so we will want to create a dependency on all the jobs in the queue. We can do this by making a copy of `consol_jobs.sh` and naming it `consol_fsjobs.sh`.

## 11.
In `consol_fsjobs.sh`, replace `/data/src/PyHipp/ec2snapshot.sh` in Line 17 with `/data/src/PyHipp/fsall-slurm.sh`.

> <p class="task"> Task
>
> Include a screenshot of the completed `consol_fsjobs.sh` script in your lab report.

You might want to push your changes to your repository on GitHub again at this point.


## 12.
We can submit the `freq-slurm.sh` script from the head node by finding all the channel directories, and changing to each directory to submit the slurm script:

```shell
(env1) [ec2-user@ip-10-0-5-43 data] $ cd /data/picasso

(env1) [ec2-user@ip-10-0-5-43 picasso] $ cwd=`pwd`; for i in `find 2018110? -name "channel*" | grep -v -e eye -e mountains | sort`; do echo $i; cd $i; sbatch /data/src/PyHipp/freq-slurm.sh; cd $cwd; done
```

This series of commands will first save the current directory in a shell variable named `cwd`, find directories named `channel*` starting from directories `20181101`, `20181102`, or `20181105`, remove directories with eye or mountains in their path, and arrange the directories in order. For each of those directories found, the name will first be printed, before we change to the directory, submit the `freq-slurm.sh` script, before returning to the `cwd` directory.

## 13.
We can now submit `consol_fsjobs.sh` by doing:

```shell
(env1) [ec2-user@ip-10-0-5-43 picasso] $ bash /data/src/PyHipp/consol_fsjobs.sh
```

You can continue with the next section while waiting for the jobs to finish.

## 14.
Once the jobs are done, you can copy the saved objects (`freqspectrum_9c80.hkl` and `freqspectrum_660e.hkl` in the `/data/picasso directory`) to your computer.

## 15.
You can update your snapshot from your EC2 instance, and then delete the cluster manually.

